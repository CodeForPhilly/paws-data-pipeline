{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAWS Data Pipeline\n",
    "The objective of this script is to create a master data table that links all the PAWS datasources together.\n",
    "## Pipeline sections\n",
    "0. Import libraries\n",
    "1. Create & populate database \n",
    "2. Create ***metadata master table*** schema to link all source tables together & populate with one of the dataset (e.g. SalesForce)\n",
    "3. For each dataset, merge each record with the ***metadata master table***. If a match is found, link the two sources. If not, create a new record. <br/>\n",
    "    a. Petpoint<br/>\n",
    "    b. Volgistics<br/>\n",
    "    c. Other - TBD<br/>\n",
    "4. Write the new table to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create & populate database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to or create database\n",
    "\n",
    "conn = sqlite3.connect(\"./sample_data/paws.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading a csv into a database table or \"updating\" the table by dropping it and recreating it with the csv\n",
    "\n",
    "def load_to_sqlite(csv_name, table_name, connection, drop_first_col=False):\n",
    "    \n",
    "    # load csv into a dataframe\n",
    "    df = pd.read_csv(csv_name, encoding='cp1252')\n",
    "    \n",
    "    # drop the first column - so far all csvs have had a first column that's an index and doesn't have a name\n",
    "    if drop_first_col:\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    # strip whitespace and periods from headers, convert to lowercase\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df.columns = df.columns.map(lambda x: re.sub(r'\\.+', '_', x))\n",
    "    \n",
    "    # create a cursor object, and use it to drop the table if it exists\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f'DROP TABLE {table_name}')\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    # load dataframe into database table\n",
    "    df.to_sql(table_name, connection, index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load petpoint\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_petpoint_deidentified.csv', 'petpoint', conn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load volgistics\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_volgistics_deidentified.csv', 'volgistics', conn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load salesforce contacts\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_salesforceContacts_deidentified.csv', 'salesforcecontacts', conn, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsalorio/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3248: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# load salesforce donations\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_salesforceDonations_deidentified.csv', 'salesforcedonations', conn, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create ***metadata master table*** schema to link all source tables together & populate with one of the dataset (e.g. SalesForce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_name</th>\n",
       "      <th>contact_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>title</th>\n",
       "      <th>mailing_street</th>\n",
       "      <th>mailing_city</th>\n",
       "      <th>mailing_state_province</th>\n",
       "      <th>mailing_zip_postal_code</th>\n",
       "      <th>mailing_country</th>\n",
       "      <th>phone</th>\n",
       "      <th>fax</th>\n",
       "      <th>mobile</th>\n",
       "      <th>email</th>\n",
       "      <th>account_owner</th>\n",
       "      <th>account_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60182</th>\n",
       "      <td>Angelica el-Ashraf Bistro</td>\n",
       "      <td>0033p00002UO8dB</td>\n",
       "      <td>Angelica</td>\n",
       "      <td>el-Ashraf</td>\n",
       "      <td>None</td>\n",
       "      <td>1417 Estate</td>\n",
       "      <td>Fontana</td>\n",
       "      <td>Pennsvania</td>\n",
       "      <td>19119-3111</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>pxm@bnygeuzhvo.ewu</td>\n",
       "      <td>PAWS Development</td>\n",
       "      <td>0013p00001pVtVy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60183</th>\n",
       "      <td>Cassondra el-Kamal Household</td>\n",
       "      <td>0033p00002UO8ed</td>\n",
       "      <td>Cassondra</td>\n",
       "      <td>el-Kamal</td>\n",
       "      <td>None</td>\n",
       "      <td>2210 S. 14st Street</td>\n",
       "      <td>West Portsmouth</td>\n",
       "      <td>NH</td>\n",
       "      <td>19125-3329</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ske@ciqgr.ndf</td>\n",
       "      <td>PAWS Development</td>\n",
       "      <td>0013p00001pVtWX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60184</th>\n",
       "      <td>Justin Campbell Bistro</td>\n",
       "      <td>0033p00002UO8oS</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>None</td>\n",
       "      <td>4074 S. 41rd St.</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19474-0204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>faxh@lcume.enj</td>\n",
       "      <td>Jared Hupp</td>\n",
       "      <td>0013p00001pVtaP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60185</th>\n",
       "      <td>Aslam Wilson Household</td>\n",
       "      <td>0033p00002UO8q2</td>\n",
       "      <td>Aslam</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>None</td>\n",
       "      <td>222 n Columbus blvd</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>BC</td>\n",
       "      <td>17009</td>\n",
       "      <td>US</td>\n",
       "      <td>4146143364</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tpik@wotkn.qwi</td>\n",
       "      <td>PAWS Development</td>\n",
       "      <td>0013p00001pVtaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60186</th>\n",
       "      <td>Dashawn Patterson Household</td>\n",
       "      <td>0033p00002UO8tB</td>\n",
       "      <td>Dashawn</td>\n",
       "      <td>Patterson</td>\n",
       "      <td>None</td>\n",
       "      <td>311</td>\n",
       "      <td>High Bridge</td>\n",
       "      <td>WA</td>\n",
       "      <td>19064-3130</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>nobcuvj@blyh.zva</td>\n",
       "      <td>Jared Hupp</td>\n",
       "      <td>0013p00001pVtbS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       account_name       contact_id first_name  last_name  \\\n",
       "60182     Angelica el-Ashraf Bistro  0033p00002UO8dB   Angelica  el-Ashraf   \n",
       "60183  Cassondra el-Kamal Household  0033p00002UO8ed  Cassondra   el-Kamal   \n",
       "60184        Justin Campbell Bistro  0033p00002UO8oS     Justin   Campbell   \n",
       "60185        Aslam Wilson Household  0033p00002UO8q2      Aslam     Wilson   \n",
       "60186   Dashawn Patterson Household  0033p00002UO8tB    Dashawn  Patterson   \n",
       "\n",
       "      title       mailing_street     mailing_city mailing_state_province  \\\n",
       "60182  None          1417 Estate          Fontana             Pennsvania   \n",
       "60183  None  2210 S. 14st Street  West Portsmouth                     NH   \n",
       "60184  None     4074 S. 41rd St.            Ocean                  Texas   \n",
       "60185  None  222 n Columbus blvd        New Haven                     BC   \n",
       "60186  None                 311       High Bridge                     WA   \n",
       "\n",
       "      mailing_zip_postal_code mailing_country       phone   fax mobile  \\\n",
       "60182              19119-3111              US        None  None   None   \n",
       "60183              19125-3329              US        None  None   None   \n",
       "60184              19474-0204            None        None  None   None   \n",
       "60185                   17009              US  4146143364  None   None   \n",
       "60186              19064-3130            None        None  None   None   \n",
       "\n",
       "                    email     account_owner       account_id  \n",
       "60182  pxm@bnygeuzhvo.ewu  PAWS Development  0013p00001pVtVy  \n",
       "60183       ske@ciqgr.ndf  PAWS Development  0013p00001pVtWX  \n",
       "60184      faxh@lcume.enj        Jared Hupp  0013p00001pVtaP  \n",
       "60185      tpik@wotkn.qwi  PAWS Development  0013p00001pVtaj  \n",
       "60186    nobcuvj@blyh.zva        Jared Hupp  0013p00001pVtbS  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from salesforcecontacts', conn).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name_first_name</th>\n",
       "      <th>first_name_last_name</th>\n",
       "      <th>title_first_name_last_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>title</th>\n",
       "      <th>nickname</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>spare_checkbox_5</th>\n",
       "      <th>spare_checkbox_6</th>\n",
       "      <th>volunteer_distribution_list</th>\n",
       "      <th>general_volunteer_emails</th>\n",
       "      <th>schedule_reminders</th>\n",
       "      <th>my_availability_is</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>i_would_like_to_serve_up_to</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Lo, Max</td>\n",
       "      <td>Max Lo</td>\n",
       "      <td>Ms. Max Lo</td>\n",
       "      <td>Lo</td>\n",
       "      <td>Max</td>\n",
       "      <td>None</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>None</td>\n",
       "      <td>Active</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>Johnson, Jessica</td>\n",
       "      <td>Jessica Johnson</td>\n",
       "      <td>Jessica Johnson</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Active</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>Williams, Bryce</td>\n",
       "      <td>Bryce Williams</td>\n",
       "      <td>Bryce Williams</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Bryce</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>They/them pronouns please</td>\n",
       "      <td>Active</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>Turner, Kaelyn</td>\n",
       "      <td>Kaelyn Turner</td>\n",
       "      <td>Ms. Kaelyn Turner</td>\n",
       "      <td>Turner</td>\n",
       "      <td>Kaelyn</td>\n",
       "      <td>None</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>None</td>\n",
       "      <td>Active</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>el-Majeed, Carolina</td>\n",
       "      <td>Carolina el-Majeed</td>\n",
       "      <td>Ms. Carolina el-Majeed</td>\n",
       "      <td>el-Majeed</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>None</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>None</td>\n",
       "      <td>Active</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last_name_first_name first_name_last_name title_first_name_last_name  \\\n",
       "1237              Lo, Max               Max Lo                 Ms. Max Lo   \n",
       "1238     Johnson, Jessica      Jessica Johnson            Jessica Johnson   \n",
       "1239      Williams, Bryce       Bryce Williams             Bryce Williams   \n",
       "1240       Turner, Kaelyn        Kaelyn Turner          Ms. Kaelyn Turner   \n",
       "1241  el-Majeed, Carolina   Carolina el-Majeed     Ms. Carolina el-Majeed   \n",
       "\n",
       "      last_name first_name middle_name title                   nickname  \\\n",
       "1237         Lo        Max        None   Ms.                       None   \n",
       "1238    Johnson    Jessica        None  None                       None   \n",
       "1239   Williams      Bryce        None  None  They/them pronouns please   \n",
       "1240     Turner     Kaelyn        None   Ms.                       None   \n",
       "1241  el-Majeed   Carolina        None   Ms.                       None   \n",
       "\n",
       "      status  type  ... spare_checkbox_5 spare_checkbox_6  \\\n",
       "1237  Active  None  ...             None             None   \n",
       "1238  Active  None  ...             None             None   \n",
       "1239  Active  None  ...             None             None   \n",
       "1240  Active  None  ...             None             None   \n",
       "1241  Active  None  ...             None             None   \n",
       "\n",
       "     volunteer_distribution_list general_volunteer_emails schedule_reminders  \\\n",
       "1237                         Yes                     None                Yes   \n",
       "1238                         Yes                     None                Yes   \n",
       "1239                         Yes                     None                Yes   \n",
       "1240                         Yes                     None                Yes   \n",
       "1241                         Yes                     None                Yes   \n",
       "\n",
       "      my_availability_is  from    to i_would_like_to_serve_up_to hours  \n",
       "1237                None  None  None                           0  None  \n",
       "1238                None  None  None                           0  None  \n",
       "1239                None  None  None                           0  None  \n",
       "1240                None  None  None                           0  None  \n",
       "1241                None  None  None                           0  None  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from volgistics', conn).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entry(entry):\n",
    "    \"\"\"\n",
    "    Function to clean up all values returned from the SQL statement, so this \n",
    "    should be performed on every entry in the dataframe with an applymap\n",
    "    \n",
    "    1 Change 'None' or 'NaN' value to an empty string\n",
    "    2 Cast value as string\n",
    "    3 Lowercase value\n",
    "    3 Strip leading and trailing white space\n",
    "    4 Remove punctuation by only keeping letters, numbers and white space\n",
    "    5 Replace internal multiple consecutive white spaces with a single white space\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert None and NaN to an empty string\n",
    "    if entry ==  None or entry == np.nan:\n",
    "        entry = ''\n",
    "    \n",
    "    # convert to string, lowercase, and strip leading and trailing whitespace\n",
    "    entry = str(entry).lower().strip()\n",
    "    \n",
    "    # remove all non alphanumeric characters except white space\n",
    "    alphanumeric_and_space = ' 1234567890abcdefghijklmnopqrstuvwxyz'\n",
    "    entry = ''.join([c for c in entry if c in alphanumeric_and_space])\n",
    "    \n",
    "    # cut down (internal) consecutive whitespaces to one white space\n",
    "    entry = re.sub(r'\\s+', ' ', entry)\n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_master_df(connection, query, *addl_columns):\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe placeholder with key meta-data to fuzzy-match\n",
    "    the users from different datasets.\n",
    "    \n",
    "    Pseudo-code:\n",
    "        Create a blank pandas dataframe (e.g. pd.DataFrame) with columns for\n",
    "        Name (last, first), address, zip code, phone number, email, etc.\n",
    "        \n",
    "        Include \"ID\" fields for each of the datasets that will be merged.\n",
    "        \n",
    "        Populate/Initialize the dataframe with data from one of the datasets\n",
    "        (e.g. Salesforce)\n",
    "    \"\"\"\n",
    "    \n",
    "    # pull the dataframe from SQL database, call cleaning function, \n",
    "    # and add empty columns for the datasets that will be merged\n",
    "    df = pd.read_sql(query, connection)\n",
    "    df = df.applymap(clean_entry)\n",
    "    \n",
    "    for col_name in addl_columns:\n",
    "        df[col_name] = np.nan\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_states(state,  min_score=.8):\n",
    "    \"\"\"\n",
    "    Taking a state or territory's name as its argument, this function returns \n",
    "    the 2 letter postal abbreviation. Since the data is human input and \n",
    "    often misspelled, it relies on a fuzzy match based on the Levenshtein \n",
    "    Distance. \n",
    "    \n",
    "    If the fuzzy match score is above a minimum (defaulting to 80%) it \n",
    "    selects the top match, otherwise it returns a blank.\n",
    "    \"\"\"\n",
    "    \n",
    "    state_abbr_dict = {'alabama': 'al',\n",
    "                     'alaska': 'ak',\n",
    "                     'arizona': 'az',\n",
    "                     'arkansas': 'ar',\n",
    "                     'california': 'ca',\n",
    "                     'colorado': 'co',\n",
    "                     'connecticut': 'ct',\n",
    "                     'delaware': 'de',\n",
    "                     'florida': 'fl',\n",
    "                     'georgia': 'ga',\n",
    "                     'hawaii': 'hi',\n",
    "                     'idaho': 'id',\n",
    "                     'illinois': 'il',\n",
    "                     'indiana': 'in',\n",
    "                     'iowa': 'ia',\n",
    "                     'kansas': 'ks',\n",
    "                     'kentucky': 'ky',\n",
    "                     'louisiana': 'la',\n",
    "                     'maine': 'me',\n",
    "                     'maryland': 'md',\n",
    "                     'massachusetts': 'ma',\n",
    "                     'michigan': 'mi',\n",
    "                     'minnesota': 'mn',\n",
    "                     'mississippi': 'ms',\n",
    "                     'missouri': 'mo',\n",
    "                     'montana': 'mt',\n",
    "                     'nebraska': 'ne',\n",
    "                     'nevada': 'nv',\n",
    "                     'new hampshire': 'nh',\n",
    "                     'new jersey': 'nj',\n",
    "                     'new mexico': 'nm',\n",
    "                     'new york': 'ny',\n",
    "                     'north carolina': 'nc',\n",
    "                     'north dakota': 'nd',\n",
    "                     'ohio': 'oh',\n",
    "                     'oklahoma': 'ok',\n",
    "                     'oregon': 'or',\n",
    "                     'pennsylvania': 'pa',\n",
    "                     'rhode island': 'ri',\n",
    "                     'south carolina': 'sc',\n",
    "                     'south dakota': 'sd',\n",
    "                     'tennessee': 'tn',\n",
    "                     'texas': 'tx',\n",
    "                     'utah': 'ut',\n",
    "                     'vermont': 'vt',\n",
    "                     'virginia': 'va',\n",
    "                     'washington': 'wa',\n",
    "                     'west virginia': 'wv',\n",
    "                     'wisconsin': 'wi',\n",
    "                     'wyoming': 'wy',\n",
    "                     'american samoa': 'as',\n",
    "                     'district of columbia': 'dc',\n",
    "                     'washington dc': 'dc',\n",
    "                     'washington district of columbia': 'dc',\n",
    "                     'federated states of micronesia': 'fm',\n",
    "                     'guam': 'gu',\n",
    "                     'marshall islands': 'mh',\n",
    "                     'northern mariana islands': 'mp',\n",
    "                     'palau': 'pw',\n",
    "                     'puerto rico': 'pr',\n",
    "                     'virgin islands': 'vi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>mobile</th>\n",
       "      <th>email</th>\n",
       "      <th>volgistics_id</th>\n",
       "      <th>petpoint_id</th>\n",
       "      <th>sf_donations_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiyota, loren</td>\n",
       "      <td>704 wynnemoor way orinda co 7701 us</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>pzvbscf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trujillo, lisa</td>\n",
       "      <td>moore rd</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thomas, jade</td>\n",
       "      <td>220 annin st malvern pennsylvania 20009 us</td>\n",
       "      <td>1276261767</td>\n",
       "      <td>714 7111110</td>\n",
       "      <td>mvkbtwogprgvqkuedegp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rascon, hannah</td>\n",
       "      <td>150 chestnut st scotch plain in 186403525 us</td>\n",
       "      <td>544 5554550</td>\n",
       "      <td>141 3431454</td>\n",
       "      <td>xebqfclvopqfrhgzkuoxzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flores, robert</td>\n",
       "      <td>5818 bristol tokyo 191232316 us</td>\n",
       "      <td>2352355555</td>\n",
       "      <td></td>\n",
       "      <td>rapwxnkoltkpect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wong, kale</td>\n",
       "      <td>6555 north hartland baden wrttemberg 60612 us</td>\n",
       "      <td>3355333533</td>\n",
       "      <td></td>\n",
       "      <td>hemqwzutgcdyhdy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tafoya, sean</td>\n",
       "      <td>27 edgewater drive home id 60643 us</td>\n",
       "      <td>1421154224</td>\n",
       "      <td></td>\n",
       "      <td>ajetbxfnszbimqcdumji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donthinani, faadil</td>\n",
       "      <td>404 e redondo ave sagamore hills dc 191461048 us</td>\n",
       "      <td>33453343334</td>\n",
       "      <td></td>\n",
       "      <td>frmapoyko</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frudden, nulong</td>\n",
       "      <td>3313 s quince street reading or 193421415 us</td>\n",
       "      <td>5565151110</td>\n",
       "      <td></td>\n",
       "      <td>phtbanpzjjhr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hebert, alan</td>\n",
       "      <td>200 n carroll street natick wa 191451655 us</td>\n",
       "      <td>668 1118081</td>\n",
       "      <td></td>\n",
       "      <td>myxhgodzfdoliabgv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                           address  \\\n",
       "0       kiyota, loren               704 wynnemoor way orinda co 7701 us   \n",
       "1      trujillo, lisa                                          moore rd   \n",
       "2        thomas, jade        220 annin st malvern pennsylvania 20009 us   \n",
       "3      rascon, hannah      150 chestnut st scotch plain in 186403525 us   \n",
       "4      flores, robert                   5818 bristol tokyo 191232316 us   \n",
       "5          wong, kale     6555 north hartland baden wrttemberg 60612 us   \n",
       "6        tafoya, sean               27 edgewater drive home id 60643 us   \n",
       "7  donthinani, faadil  404 e redondo ave sagamore hills dc 191461048 us   \n",
       "8     frudden, nulong      3313 s quince street reading or 193421415 us   \n",
       "9        hebert, alan       200 n carroll street natick wa 191451655 us   \n",
       "\n",
       "         phone       mobile                   email  volgistics_id  \\\n",
       "0                                           pzvbscf            NaN   \n",
       "1                                                              NaN   \n",
       "2   1276261767  714 7111110    mvkbtwogprgvqkuedegp            NaN   \n",
       "3  544 5554550  141 3431454  xebqfclvopqfrhgzkuoxzi            NaN   \n",
       "4   2352355555                      rapwxnkoltkpect            NaN   \n",
       "5   3355333533                      hemqwzutgcdyhdy            NaN   \n",
       "6   1421154224                 ajetbxfnszbimqcdumji            NaN   \n",
       "7  33453343334                            frmapoyko            NaN   \n",
       "8   5565151110                         phtbanpzjjhr            NaN   \n",
       "9  668 1118081                    myxhgodzfdoliabgv            NaN   \n",
       "\n",
       "   petpoint_id  sf_donations_id  \n",
       "0          NaN              NaN  \n",
       "1          NaN              NaN  \n",
       "2          NaN              NaN  \n",
       "3          NaN              NaN  \n",
       "4          NaN              NaN  \n",
       "5          NaN              NaN  \n",
       "6          NaN              NaN  \n",
       "7          NaN              NaN  \n",
       "8          NaN              NaN  \n",
       "9          NaN              NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create master dataframe using the 'salesforcecontacts' table\n",
    "\n",
    "sf_cont_query = \"\"\"SELECT    last_name\n",
    "                             , first_name \n",
    "                             , mailing_street as street\n",
    "                             , mailing_city as city\n",
    "                             , mailing_state_province as state_etc \n",
    "                             , mailing_zip_postal_code as zipcode\n",
    "                             , mailing_country as country\n",
    "                             , phone\n",
    "                             , mobile\n",
    "                             , email\n",
    "                    FROM     salesforcecontacts\"\"\"\n",
    "\n",
    "### cleanup still to do in pandas ###\n",
    "# street needs to have formatting standardized (eg 19th st vs 19 st, n vs north)- probably want to always go with the shorter version. this will be onerous, but maybe there's a library on github for this. Some of this will just be stripping to letters and numbers, then looking for names like south, avenue, apartment etec and making them the abbreviation- there must be a list of these things, actually Jonathan might have given me code with that list\n",
    "# some states are written as full names, some as abbreviations- this won't be so bad, make everything 2 letters, have all fifty states, get a distance score or percentage, take the top one if it's above a cutoff, otherwise leave it blank\n",
    "\n",
    "master_df = create_user_master_df(conn, sf_cont_query, 'volgistics_id', 'petpoint_id', 'sf_donations_id')\n",
    "\n",
    "# combine last and first names to make a single name column\n",
    "master_df['name'] = master_df['last_name'] + ', ' + master_df['first_name']\n",
    "\n",
    "# standardize state and territory names to their 2 letter postal abbreviation\n",
    "master_df['state_etc'] = master_df['state_etc'].apply(standardize_states)\n",
    "\n",
    "# make a single address column\n",
    "master_df['address'] = (master_df['street'] + ' ' + master_df['city'] + ' ' + master_df['state_etc'] + ' ' + master_df['zipcode'] + ' ' + master_df['country']).str.strip()\n",
    "# drop extraneous address columns\n",
    "master_df = master_df[['name', 'address', 'phone', 'mobile', 'email', 'volgistics_id', 'petpoint_id', 'sf_donations_id']]\n",
    "\n",
    "master_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each dataset, merge each record with the ***metadata master table***\n",
    "If a match is found, link the two sources. If not, create a new record. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(new_df, master_df):\n",
    "    \"\"\"\n",
    "    This function merges each new dataset with the metadata master table by\n",
    "    going line-by-line on the new dataset and looking for a match in the \n",
    "    existing metadata master dataset. If a match is found\n",
    "    \n",
    "    Pseudo-code:\n",
    "        LOOP: For each line in the new_df, compare that line against all lines in \n",
    "        the master_df. \n",
    "        \n",
    "        LOGIC: For each comparison, generate (a) a fuzzy-match score on name,\n",
    "        (b) T/F on whether zip-code matches, (c) T/F on whether email matches,\n",
    "        (d) T/F on whether phone number matches.\n",
    "        \n",
    "        OUTPUT: For each comparison if the fuzzy-match score is above a threshold (e.g. >=90%)\n",
    "        and (b), (c) or (d) matches, consider it a match and add the new dataset \n",
    "        id to the existing record. If it doesn't match, create a new record in the\n",
    "        master dataset.\n",
    "        \n",
    "    Note: there's probably a more efficient way to do this (vs. going line-by-line)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A Petpoint merge \n",
    "Apply function above the Petpoint dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B Volgistics merge\n",
    "Apply function above the Volgistics dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.C Other - TBD - Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write the new table to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_to_sqlite(master_df, master_table, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other - placeholder - graveyard\n",
    "Graveyard/placeholder code from previous sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple join to check that it worked and the tables can be queried\n",
    "\n",
    "df = pd.read_sql('''select * from petpoint as pp \n",
    "                    join volgistics as vol \n",
    "                    on pp.\"unnamed:_0\" = vol.\"unnamed:_0\"\n",
    "\n",
    "                    join (SELECT * FROM salesforcecontacts AS sf_contacts\n",
    "                            JOIN salesforcedonations AS sf_donations\n",
    "                            ON sf_contacts.\"Account_ID\" = sf_donations.\"Account_ID\") as sf\n",
    "                    on pp.\"unnamed:_0\" = sf.\"unnamed:_0\"\n",
    "                    \n",
    "                    ''', conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data matching on (first name + last name)\n",
    "\n",
    "df2 = pd.read_sql('''SELECT * FROM petpoint AS pp\n",
    "                     INNER JOIN volgistics AS vol ON pp.\"Intake_Record_Owner\" = vol.\"First_name_Last_name\"\n",
    "                     INNER JOIN (SELECT * FROM salesforcecontacts AS sf_contacts\n",
    "                            JOIN salesforcedonations AS sf_donations\n",
    "                            ON sf_contacts.\"Account_ID\" = sf_donations.\"Account_ID\") AS sf\n",
    "                     ON pp.\"Intake_Record_Owner\" = (sf.\"First_Name\" + \" \" + sf.\"Last_Name\")\n",
    "                  ''', conn)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close database connection\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
