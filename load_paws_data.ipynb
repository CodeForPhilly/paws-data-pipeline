{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAWS Data Pipeline\n",
    "The objective of this script is to create a master data table that links all the PAWS datasources together.\n",
    "## Pipeline sections\n",
    "0. Import libraries\n",
    "1. Create & populate database \n",
    "2. Create ***metadata master table*** schema to link all source tables together & populate with one of the dataset (e.g. SalesForce)\n",
    "3. For each dataset, merge each record with the ***metadata master table***. If a match is found, link the two sources. If not, create a new record. <br/>\n",
    "    a. Petpoint<br/>\n",
    "    b. Volgistics<br/>\n",
    "    c. Other - TBD<br/>\n",
    "4. Write the new table to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create & populate database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to or create database\n",
    "\n",
    "conn = sqlite3.connect(\"./sample_data/paws.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading a csv into a database table or \"updating\" the table by dropping it and recreating it with the csv\n",
    "\n",
    "def load_to_sqlite(csv_name, table_name, connection):\n",
    "    \n",
    "    # load csv into a dataframe\n",
    "    df = pd.read_csv(csv_name, encoding='cp1252')\n",
    "    \n",
    "    # strip whitespace and periods from headers, convert to lowercase\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df.columns = df.columns.map(lambda x: re.sub(r'\\.+', '_', x))\n",
    "    \n",
    "    # create a cursor object, and use it to drop the table if it exists\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f'DROP TABLE {table_name}')\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    # load dataframe into database table\n",
    "    df.to_sql(table_name, connection, index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load petpoint\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_petpoint_deidentified.csv', 'petpoint', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load volgistics\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_volgistics_deidentified.csv', 'volgistics', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load salesforce contacts\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_salesforceContacts_deidentified.csv', 'salesforcecontacts', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load salesforce donations\n",
    "\n",
    "load_to_sqlite('./sample_data/CfP_PDP_salesforceDonations_deidentified.csv', 'salesforcedonations', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create ***metadata master table*** schema to link all source tables together & populate with one of the dataset (e.g. SalesForce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_master_df():\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe placeholder with key meta-data to fuzzy-match\n",
    "    the users from different datasets.\n",
    "    \n",
    "    Pseudo-code:\n",
    "        Create a blank pandas dataframe (e.g. pd.DataFrame) with columns for\n",
    "        Name (first, last), address, zip code, phone number, email, etc.\n",
    "        \n",
    "        Include \"ID\" fields for each of the datasets that will be merged.\n",
    "        \n",
    "        Populate/Initialize the dataframe with data from one of the datasets\n",
    "        (e.g. Salesforce)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each dataset, merge each record with the ***metadata master table***\n",
    "If a match is found, link the two sources. If not, create a new record. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_merge(new_df, master_df):\n",
    "    \"\"\"\n",
    "    This function merges each new dataset with the metadata master table by\n",
    "    going line-by-line on the new dataset and looking for a match in the \n",
    "    existing metadata master dataset. If a match is found\n",
    "    \n",
    "    Pseudo-code:\n",
    "        LOOP: For each line in the new_df, compare that line against all lines in \n",
    "        the master_df. \n",
    "        \n",
    "        LOGIC: For each comparison, generate (a) a fuzzy-match score on name,\n",
    "        (b) T/F on whether zip-code matches, (c) T/F on whether email matches,\n",
    "        (d) T/F on whether phone number matches.\n",
    "        \n",
    "        OUTPUT: For each comparison if the fuzzy-match score is above a threshold (e.g. >=90%)\n",
    "        and (b), (c) or (d) matches, consider it a match and add the new dataset \n",
    "        id to the existing record. If it doesn't match, create a new record in the\n",
    "        master dataset.\n",
    "        \n",
    "    Note: there's probably a more efficient way to do this (vs. going line-by-line)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A Petpoint merge \n",
    "Apply function above the Petpoint dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B Volgistics merge\n",
    "Apply function above the Volgistics dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.C Other - TBD - Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write the new table to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_to_sqlite(master_df, master_table, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other - placeholder - graveyard\n",
    "Graveyard/placeholder code from previous sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple join to check that it worked and the tables can be queried\n",
    "\n",
    "df = pd.read_sql('''select * from petpoint as pp \n",
    "                    join volgistics as vol \n",
    "                    on pp.\"unnamed:_0\" = vol.\"unnamed:_0\"\n",
    "\n",
    "                    join (SELECT * FROM salesforcecontacts AS sf_contacts\n",
    "                            JOIN salesforcedonations AS sf_donations\n",
    "                            ON sf_contacts.\"Account_ID\" = sf_donations.\"Account_ID\") as sf\n",
    "                    on pp.\"unnamed:_0\" = sf.\"unnamed:_0\"\n",
    "                    \n",
    "                    ''', conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data matching on (first name + last name)\n",
    "\n",
    "df2 = pd.read_sql('''SELECT * FROM petpoint AS pp\n",
    "                     INNER JOIN volgistics AS vol ON pp.\"Intake_Record_Owner\" = vol.\"First_name_Last_name\"\n",
    "                     INNER JOIN (SELECT * FROM salesforcecontacts AS sf_contacts\n",
    "                            JOIN salesforcedonations AS sf_donations\n",
    "                            ON sf_contacts.\"Account_ID\" = sf_donations.\"Account_ID\") AS sf\n",
    "                     ON pp.\"Intake_Record_Owner\" = (sf.\"First_Name\" + \" \" + sf.\"Last_Name\")\n",
    "                  ''', conn)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close database connection\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
