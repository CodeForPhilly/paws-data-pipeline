{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAWS Data Pipeline\n",
    "The objective of this script is to create a master data table that links all the PAWS datasources together.\n",
    "## Pipeline sections\n",
    "0. Import libraries\n",
    "1. Create & populate database \n",
    "2. Create ***metadata master table*** schema to link all source tables together & populate with one of the dataset (e.g. SalesForce)\n",
    "3. For each dataset, merge each record with the ***metadata master table***. If a match is found, link the two sources. If not, create a new record. <br/>\n",
    "    a. Petpoint<br/>\n",
    "    b. Volgistics<br/>\n",
    "    c. Other - TBD<br/>\n",
    "4. Write the new table to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from functools import reduce\n",
    "from postal.expand import expand_address\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install postal:\n",
    "\n",
    "https://github.com/openvenues/pypostal\n",
    "\n",
    "There's a version on conda forge but it doesn't look up to date with the newer releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and clean columns\n",
    "def import_csv_and_clean_cols(csv, drop_first_col=False):\n",
    "    \n",
    "    df = pd.read_csv(csv, encoding='cp1252', dtype=str)\n",
    "    \n",
    "    # drop the first column - so far all csvs have had a first column that's an index and doesn't have a name\n",
    "    if drop_first_col:\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "    \n",
    "    # strip whitespace and periods from headers, convert to lowercase\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    df.columns = df.columns.map(lambda x: re.sub(r'\\s+', '_', x))\n",
    "    df.columns = df.columns.map(lambda x: re.sub(r'\\.+', '_', x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entries(entry):\n",
    "    \"\"\"\n",
    "    1 Change 'None' or 'NaN' value to an empty string\n",
    "    2 Cast value as string\n",
    "    3 Lowercase value\n",
    "    3 Strip leading and trailing white space\n",
    "    4 Replace internal multiple consecutive white spaces with a single white space\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert None and NaN to an empty string. This allows simple string concatenation\n",
    "    if pd.isnull(entry):\n",
    "        entry = ''\n",
    "    \n",
    "    # convert to string, lowercase, and strip leading and trailing whitespace\n",
    "    entry = str(entry).lower().strip()\n",
    "    \n",
    "    # cut down (internal) consecutive whitespaces to one white space\n",
    "    entry = re.sub(r'\\s+', ' ', entry)\n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_symbols(char_string, kept_chars = '- 1234567890abcdefghijklmnopqrstuvwxyz'):\n",
    "    \n",
    "    '''\n",
    "    strip all characters from the passed string that are not specified in kept_chars.\n",
    "    the base case keeps only letters, numbers, spaces, and dashes.\n",
    "    while this is fine for most string entries, the default selection is not appropriate for \n",
    "    all entries. For instance, email addresses can contain various characters and are best left intact.\n",
    "    '''\n",
    "\n",
    "    return ''.join([c for c in char_string if c in kept_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_address_columns(address_columns):\n",
    "    return reduce(lambda col_1, col_2: \n",
    "        col_1.apply(clean_entries).apply(strip_symbols) + ' ' + \n",
    "        col_2.apply(clean_entries).apply(strip_symbols), address_columns).apply(clean_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe into database table, drop and replace the table if it exists\n",
    "def load_to_sqlite(df, table_name, connection):\n",
    "    df.to_sql(table_name, connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to or create database\n",
    "conn = sqlite3.connect(\"./sample_data/paws.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# petpoint\n",
    "# I acknowledge that dumping this list to json is not the right thing to do with an RDBMS, but here we are. To read back to a list run json.loads()\n",
    "\n",
    "petpoint_df = import_csv_and_clean_cols('./sample_data/CfP_PDP_petpoint_deidentified.csv', drop_first_col=True)\n",
    "\n",
    "petpoint_df['match_name'] = petpoint_df['outcome_person_name'].apply(clean_entries).apply(strip_symbols)\n",
    "petpoint_df['match_email'] = petpoint_df['out_email'].apply(clean_entries)\n",
    "petpoint_df['match_cell'] = petpoint_df['out_cell_phone'].apply(clean_entries).apply(strip_symbols)\n",
    "petpoint_df['match_phone'] = petpoint_df['out_home_phone'].apply(clean_entries).apply(strip_symbols)\n",
    "\n",
    "addr_components = [petpoint_df['out_street_name'], petpoint_df['out_street_type'], petpoint_df['out_street_direction'], petpoint_df['out_street_direction2'], petpoint_df['out_unit_number'], petpoint_df['out_city'], petpoint_df['out_province'], petpoint_df['out_postal_code'].fillna('').apply(str).str[:5]]\n",
    "petpoint_df['match_address_list'] = combine_address_columns(addr_components)\n",
    "petpoint_df['match_address_list'] = petpoint_df['match_address_list'].apply(expand_address, languages=['en']).apply(json.dumps)\n",
    "\n",
    "load_to_sqlite(petpoint_df, 'petpoint', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volgistics\n",
    "\n",
    "volgistics_df = import_csv_and_clean_cols('./sample_data/CfP_PDP_volgistics_deidentified.csv', drop_first_col=True)\n",
    "\n",
    "volgistics_df['match_name'] = volgistics_df['last_name_first_name'].apply(clean_entries).apply(strip_symbols)\n",
    "volgistics_df['match_email'] = volgistics_df['email'].apply(clean_entries)\n",
    "volgistics_df['match_cell'] = volgistics_df['cell'].apply(clean_entries).apply(strip_symbols)\n",
    "volgistics_df['match_phone'] = volgistics_df['home'].apply(clean_entries).apply(strip_symbols)\n",
    "\n",
    "addr_components = [volgistics_df['street_1'], volgistics_df['street_2'], volgistics_df['street_3'], volgistics_df['city'], volgistics_df['state'], volgistics_df['zip'].fillna('').apply(str).str[:5]]\n",
    "volgistics_df['match_address_list'] = combine_address_columns(addr_components)\n",
    "volgistics_df['match_address_list'] = volgistics_df['match_address_list'].apply(expand_address, languages=['en']).apply(json.dumps)\n",
    "\n",
    "load_to_sqlite(volgistics_df, 'volgistics', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salesforce contacts\n",
    "\n",
    "sf_contacts_df = import_csv_and_clean_cols('./sample_data/CfP_PDP_salesforceContacts_deidentified.csv', drop_first_col=True)\n",
    "\n",
    "sf_contacts_df['match_name'] = sf_contacts_df['last_name'].apply(clean_entries).apply(strip_symbols) + ' ' + sf_contacts_df['first_name'].apply(clean_entries).apply(strip_symbols)\n",
    "sf_contacts_df['match_email'] = sf_contacts_df['email'].apply(clean_entries)\n",
    "sf_contacts_df['match_cell'] = sf_contacts_df['mobile'].apply(clean_entries).apply(strip_symbols)\n",
    "sf_contacts_df['match_phone'] = sf_contacts_df['phone'].apply(clean_entries).apply(strip_symbols)\n",
    "\n",
    "addr_components = [sf_contacts_df['mailing_street'], sf_contacts_df['mailing_city'], sf_contacts_df['mailing_state_province'], sf_contacts_df['mailing_zip_postal_code'].fillna('').apply(str).str[:5]]\n",
    "sf_contacts_df['match_address_list'] = combine_address_columns(addr_components)\n",
    "sf_contacts_df['match_address_list'] = sf_contacts_df['match_address_list'].apply(expand_address, languages=['en']).apply(json.dumps)\n",
    "\n",
    "load_to_sqlite(sf_contacts_df, 'salesforcecontacts', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salesforce donations has account and opportunity id, but no personal information. \n",
    "# I assume account_id maps to the account_id in salesforce contacts, so I'm cleaning column names and uploading the data as is\n",
    "\n",
    "sf_donations_df = import_csv_and_clean_cols('./sample_data/CfP_PDP_salesforceDonations_deidentified.csv', drop_first_col=True)\n",
    "load_to_sqlite(sf_donations_df, 'salesforcedonations', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close database connection\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
